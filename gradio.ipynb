{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2086041-398a-461c-9b8f-a6b42c0854bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gradio in c:\\users\\hp\\anaconda3\\lib\\site-packages (5.17.1)\n",
      "Requirement already satisfied: aiofiles<24.0,>=22.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from gradio) (23.2.1)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from gradio) (4.2.0)\n",
      "Requirement already satisfied: fastapi<1.0,>=0.115.2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from gradio) (0.115.8)\n",
      "Requirement already satisfied: ffmpy in c:\\users\\hp\\anaconda3\\lib\\site-packages (from gradio) (0.5.0)\n",
      "Requirement already satisfied: gradio-client==1.7.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from gradio) (1.7.1)\n",
      "Requirement already satisfied: httpx>=0.24.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from gradio) (0.27.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.28.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from gradio) (0.29.1)\n",
      "Requirement already satisfied: jinja2<4.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from gradio) (3.1.4)\n",
      "Requirement already satisfied: markupsafe~=2.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from gradio) (2.1.3)\n",
      "Requirement already satisfied: numpy<3.0,>=1.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from gradio) (1.26.4)\n",
      "Requirement already satisfied: orjson~=3.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from gradio) (3.10.15)\n",
      "Requirement already satisfied: packaging in c:\\users\\hp\\anaconda3\\lib\\site-packages (from gradio) (24.1)\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from gradio) (2.2.2)\n",
      "Requirement already satisfied: pillow<12.0,>=8.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from gradio) (10.4.0)\n",
      "Requirement already satisfied: pydantic>=2.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from gradio) (2.8.2)\n",
      "Requirement already satisfied: pydub in c:\\users\\hp\\anaconda3\\lib\\site-packages (from gradio) (0.25.1)\n",
      "Requirement already satisfied: python-multipart>=0.0.18 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from gradio) (0.0.20)\n",
      "Requirement already satisfied: pyyaml<7.0,>=5.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from gradio) (6.0.1)\n",
      "Requirement already satisfied: ruff>=0.9.3 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from gradio) (0.9.7)\n",
      "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from gradio) (0.1.6)\n",
      "Requirement already satisfied: semantic-version~=2.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from gradio) (2.10.0)\n",
      "Requirement already satisfied: starlette<1.0,>=0.40.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from gradio) (0.45.3)\n",
      "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from gradio) (0.13.2)\n",
      "Requirement already satisfied: typer<1.0,>=0.12 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from gradio) (0.15.1)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from gradio) (4.11.0)\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from gradio) (0.34.0)\n",
      "Requirement already satisfied: fsspec in c:\\users\\hp\\anaconda3\\lib\\site-packages (from gradio-client==1.7.1->gradio) (2024.6.1)\n",
      "Requirement already satisfied: websockets<15.0,>=10.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from gradio-client==1.7.1->gradio) (14.2)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from anyio<5.0,>=3.0->gradio) (3.7)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from anyio<5.0,>=3.0->gradio) (1.3.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\hp\\anaconda3\\lib\\site-packages (from httpx>=0.24.1->gradio) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\hp\\anaconda3\\lib\\site-packages (from httpx>=0.24.1->gradio) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\hp\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.28.1->gradio) (3.13.1)\n",
      "Requirement already satisfied: requests in c:\\users\\hp\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.28.1->gradio) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.28.1->gradio) (4.66.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2023.3)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pydantic>=2.0->gradio) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pydantic>=2.0->gradio) (2.20.1)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (13.7.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\hp\\anaconda3\\lib\\site-packages (from click>=8.0.0->typer<1.0,>=0.12->gradio) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.16.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.15.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.28.1->gradio) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.2.3)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3027bb4-ee33-4cf2-8d8c-175979699f12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ce5f1c28-56b8-4b64-a343-77b95b837070",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gtts\n",
      "  Downloading gTTS-2.5.4-py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: requests<3,>=2.27 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from gtts) (2.32.3)\n",
      "Requirement already satisfied: click<8.2,>=7.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from gtts) (8.1.7)\n",
      "Requirement already satisfied: colorama in c:\\users\\hp\\anaconda3\\lib\\site-packages (from click<8.2,>=7.1->gtts) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests<3,>=2.27->gtts) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests<3,>=2.27->gtts) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests<3,>=2.27->gtts) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests<3,>=2.27->gtts) (2024.8.30)\n",
      "Downloading gTTS-2.5.4-py3-none-any.whl (29 kB)\n",
      "Installing collected packages: gtts\n",
      "Successfully installed gtts-2.5.4\n"
     ]
    }
   ],
   "source": [
    "!pip install gtts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "845f6315-234a-4417-a2f8-24c55d7ec868",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\gradio\\components\\chatbot.py:285: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "Could not create share link. Please check your internet connection or our status page: https://status.gradio.app.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 448ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\gradio\\queueing.py\", line 625, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\gradio\\route_utils.py\", line 322, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\gradio\\blocks.py\", line 2106, in process_api\n",
      "    data = await self.postprocess_data(block_fn, result[\"prediction\"], state)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\gradio\\blocks.py\", line 1862, in postprocess_data\n",
      "    self.validate_outputs(block_fn, predictions)  # type: ignore\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\gradio\\blocks.py\", line 1817, in validate_outputs\n",
      "    raise ValueError(\n",
      "ValueError: A  function (video_stream_analysis) didn't return enough output values (needed: 5, returned: 3).\n",
      "    Output components:\n",
      "        [image, markdown, label, audio, textbox]\n",
      "    Output values returned:\n",
      "        [None, \"Error: Could not open video file: None\", None]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 402ms/step\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import gradio as gr\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from gtts import gTTS\n",
    "import tempfile\n",
    "\n",
    "def text_to_speech(text):\n",
    "    tts = gTTS(text)\n",
    "    temp_file = tempfile.NamedTemporaryFile(delete=False, suffix=\".mp3\")\n",
    "    temp_file_path = temp_file.name\n",
    "    tts.save(temp_file_path)\n",
    "    return temp_file_path\n",
    "\n",
    "\n",
    "\n",
    "IMAGE_SIZE = 256\n",
    "\n",
    "# Load Trained Model\n",
    "MODEL_PATH = \"plant25.h5\"  # Ensure the model is saved here\n",
    "model = tf.keras.models.load_model(MODEL_PATH)\n",
    "\n",
    "# Load Disease Information\n",
    "disease_info_path = \"disease_info.csv\"\n",
    "disease_df = pd.read_csv(disease_info_path)\n",
    "disease_dict = disease_df.set_index(\"disease_name\").to_dict(orient=\"index\")\n",
    "\n",
    "# Load Class Names\n",
    "CLASS_NAMES = ['Bacteria', 'Fungi', 'Healthy', 'Nematode', 'Pest', 'Phytopthora', 'Virus']  # Update with actual class names\n",
    "\n",
    "# Function to preprocess the image\n",
    "def preprocess_image(image):\n",
    "    image = image.resize((IMAGE_SIZE, IMAGE_SIZE))\n",
    "    image = img_to_array(image) / 255.0\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "    return image\n",
    "    \n",
    "# Function to estimate disease severity percentage\n",
    "def estimate_severity_percentage(confidence):\n",
    "    return round(confidence * 100, 2)\n",
    "\n",
    "# Function to categorize severity\n",
    "def estimate_severity(confidence):\n",
    "    if confidence > 0.75:\n",
    "        return \"Severe\"\n",
    "    elif confidence > 0.5:\n",
    "        return \"Moderate\"\n",
    "    else:\n",
    "        return \"Mild\"\n",
    "        \n",
    "def predict_leaf_disease(image):\n",
    "    img_array = preprocess_image(image)\n",
    "    prediction = model.predict(img_array)\n",
    "    predicted_class = np.argmax(prediction)\n",
    "    \n",
    "    confidence = np.max(prediction)\n",
    "    severity_percentage = estimate_severity_percentage(confidence)\n",
    "\n",
    "    disease_name = CLASS_NAMES[predicted_class]\n",
    "    severity = estimate_severity(confidence)\n",
    "    \n",
    "    disease_details = disease_dict.get(disease_name, {\"cause\": \"Unknown\", \"prevention\": \"No information available\"})\n",
    "\n",
    "   \n",
    "    result_text = (\n",
    "        f\"Disease: {disease_name}\\n\"\n",
    "        f\"Severity: {severity} ({severity_percentage}%)\\n\"\n",
    "        f\"Cause: {disease_details['cause']}\\n\"\n",
    "        f\"Prevention: {disease_details['prevention']}\"\n",
    "    )\n",
    "    \n",
    "  \n",
    "    audio_path = text_to_speech(result_text)\n",
    "\n",
    "    return result_text, disease_name, audio_path\n",
    "\n",
    "\n",
    "\n",
    "def chatbot_response(user_input):\n",
    "    user_input = user_input.strip().lower()\n",
    "    for disease, details in disease_dict.items():\n",
    "        if disease.lower() in user_input:\n",
    "            response_text = (\n",
    "                f\"Disease: {disease}\\n\"\n",
    "                f\"Cause: {details['cause']}\\n\"\n",
    "                f\"Prevention: {details['prevention']}\"\n",
    "            )\n",
    "            audio_path = text_to_speech(response_text)\n",
    "            return [(user_input, response_text)], audio_path\n",
    "    \n",
    "    default_response = \"Sorry, I couldn't find information on that disease.\"\n",
    "    audio_path = text_to_speech(default_response)\n",
    "    return [(user_input, default_response)], audio_path\n",
    "    \n",
    "\n",
    "def capture_frame():\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    if not cap.isOpened():\n",
    "        return None, \"Error: Could not open camera.\"\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    cap.release()\n",
    "\n",
    "    if not ret:\n",
    "        return None, \"Error: Could not capture frame.\"\n",
    "\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    return frame_rgb, \"Frame captured successfully.\"\n",
    "\n",
    "def is_leaf(image):\n",
    "    \"\"\"Detect if the captured image contains a leaf based on color segmentation.\"\"\"\n",
    "    image = np.array(image)\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
    "\n",
    "  \n",
    "    lower_green = np.array([25, 40, 40])   \n",
    "    upper_green = np.array([90, 255, 255])  \n",
    "\n",
    "   \n",
    "    mask = cv2.inRange(hsv, lower_green, upper_green)\n",
    "    green_percentage = (cv2.countNonZero(mask) / mask.size) * 100\n",
    "\n",
    "    return green_percentage > 10\n",
    "\n",
    "\n",
    "def real_time_camera():\n",
    "    frame, status = capture_frame()\n",
    "    if frame is None:\n",
    "        return None, status, None, None, status\n",
    "\n",
    "    pil_image = Image.fromarray(frame)\n",
    "\n",
    "   \n",
    "    if not is_leaf(pil_image):\n",
    "        result_text = \"Invalid: No leaf detected. Please capture an image of a leaf.\"\n",
    "        audio_path = text_to_speech(result_text)\n",
    "        return pil_image, result_text, \"No Leaf Detected\", audio_path, status\n",
    "\n",
    "    # If a leaf is detected, predict the disease\n",
    "    result_text, disease_name, audio_path = predict_leaf_disease(pil_image)\n",
    "\n",
    "    return pil_image, result_text, disease_name, audio_path, status\n",
    "\n",
    "\n",
    "def video_stream_analysis(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        return None, f\"Error: Could not open video file: {video_path}\", None\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        return None, \"Error: Could not read video frame.\", None\n",
    "\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    pil_image = Image.fromarray(frame_rgb)\n",
    "\n",
    "    result_text, disease_name, audio_path = predict_leaf_disease(pil_image)\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "    return pil_image, result_text, disease_name, audio_path, \"Video analysis completed.\"\n",
    "\n",
    "\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"# ðŸŒ¿ Leaf Disease Detection App\")\n",
    "    gr.Markdown(\"Upload a leaf image, use your camera, or analyze a video stream to detect diseases.\")\n",
    "\n",
    "    # Tab 1: Upload Image\n",
    "    with gr.Tab(\"Upload Image\"):\n",
    "        gr.Markdown(\"### Upload a leaf image to detect disease.\")\n",
    "        with gr.Row():\n",
    "            image_input = gr.Image(type=\"pil\", label=\"Upload Leaf Image\")\n",
    "        submit_button = gr.Button(\"Submit\", variant=\"primary\")\n",
    "        with gr.Row():\n",
    "            output_text = gr.Markdown(label=\"Prediction Result\")\n",
    "            output_label = gr.Label(label=\"Predicted Disease\")\n",
    "            audio_output = gr.Audio(label=\"Voice Output\")  # Audio output added\n",
    "        submit_button.click(\n",
    "            fn=predict_leaf_disease,\n",
    "            inputs=[image_input],\n",
    "            outputs=[output_text, output_label, audio_output]\n",
    "        )\n",
    "\n",
    "  \n",
    "    with gr.Tab(\"Real-Time Camera\"):\n",
    "        gr.Markdown(\"### Capture an image using your camera for real-time analysis.\")\n",
    "        camera_button = gr.Button(\"Capture Image\", variant=\"primary\")\n",
    "        with gr.Row():\n",
    "            camera_output = gr.Image(label=\"Captured Image\")\n",
    "            camera_text = gr.Markdown(label=\"Prediction Result\")\n",
    "            camera_label = gr.Label(label=\"Predicted Disease\")\n",
    "            camera_audio = gr.Audio(label=\"Voice Output\")\n",
    "            camera_status = gr.Textbox(label=\"Camera Status\")\n",
    "        camera_button.click(real_time_camera, outputs=[camera_output, camera_text, camera_label, camera_audio, camera_status])\n",
    "\n",
    "\n",
    "   \n",
    "    with gr.Tab(\"Video Stream Analysis\"):\n",
    "        gr.Markdown(\"### Upload a video for plant disease analysis.\")\n",
    "        video_input = gr.Video(label=\"Upload Video\")\n",
    "        video_button = gr.Button(\"Analyze Video\", variant=\"primary\")\n",
    "        with gr.Row():\n",
    "            video_output = gr.Image(label=\"Video Frame\")\n",
    "            video_text = gr.Markdown(label=\"Prediction Result\")\n",
    "            video_label = gr.Label(label=\"Predicted Disease\")\n",
    "            video_audio = gr.Audio(label=\"Voice Output\")\n",
    "            video_status = gr.Textbox(label=\"Analysis Status\")\n",
    "    video_button.click(video_stream_analysis, inputs=[video_input], outputs=[video_output, video_text, video_label, video_audio, video_status])\n",
    "        #chatboat\n",
    "    with gr.Tab(\"Chatbot\"):\n",
    "        chatbot = gr.Chatbot()\n",
    "        user_input = gr.Textbox(placeholder=\"Ask about plant diseases...\")\n",
    "        send_button = gr.Button(\"Ask\")\n",
    "        audio_output = gr.Audio(label=\"Voice Output\")  # Audio output added\n",
    "        send_button.click(chatbot_response, inputs=[user_input], outputs=[chatbot, audio_output])       \n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    demo.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ece6b01-49d9-4b5f-9450-e10b5992a934",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
